input: "data"
input_shape{dim:128 dim:25088 dim:1 dim:1} # 25088 = 512 * 7 * 7
input: "label"
input_shape{dim:128 dim:1} 

layer { name:   "fc6" type: "InnerProduct" bottom: "data" top: "fc6" param {lr_mult: 1} param {lr_mult: 2} inner_product_param{ num_output: 4096}}
layer { bottom: "fc6" top: "fc6" name: "relu6" type: "ReLU"}
layer { bottom: "fc6" top: "fc6" name: "drop6" type: "Dropout" dropout_param { dropout_ratio: 0.5 } }

layer { name:   "fc7" type: "InnerProduct" bottom: "fc6" top: "fc7" param {lr_mult: 1} param {lr_mult: 2} inner_product_param{ num_output: 4096}}
layer { bottom: "fc7" top: "fc7" name: "relu7" type: "ReLU"}
layer { bottom: "fc7" top: "fc7" name: "drop7" type: "Dropout" dropout_param { dropout_ratio: 0.5 } }

layer { name: "fc8_pascal" type: "InnerProduct" bottom: "fc7" top: "fc8_pascal" param {lr_mult: 1 decay_mult: 1.} param {lr_mult: 2 decay_mult: 0.} 
	inner_product_param{ num_output: 21 weight_filler { type: "gaussian" std: 0.01} bias_filler { type: "constant" value: 1 }}}

layer { name: "loss" type: "SoftmaxWithLoss" bottom: "fc8_pascal" bottom: "label" top: "loss"}
layer { name: "accuracy" type: "Accuracy" bottom: "fc8_pascal" bottom: "label" top: "accuracy"}

layer { name: "predictions" type: "Softmax" bottom: "fc8_pascal" top: "predictions" include: { phase: TEST } }
layer { name: "predictions_silence" type: "Silence" bottom: "predictions" include: { phase: TEST } }
